---
title: "Day 2 - Scaling up your computations"
format: html
---

# Introduction

The goal of this session is to collaboratively solve a series of challenges that will introduce you to practices that enable you scale up your computations.

The data

- (Re)introduce the Penguins data

A common challenge: Repeating things

- split, apply, combine

Several tools that can help us apply this workflow

- tidyverse: tables, group_by, summarise/mutate
- map: for lists / vectors
- ggplot: facets 
- functions


## Load libraries

We will primarily be using packages from the {tidyverse}, feel free to add more packages here to help solve the challenges.

```{r}
library(tidyverse)
library(janitor)
dir.create("output")
```


## Challenge 0 - Loading data from many files

We have just returned from an expedition from Antarctica and collected *a lot* of data from multiple species of penguins. Sometimes "we" counted the penguins.  Sometimes we didn't.  We recorded data for each species in separate `.csv` files but **we need to combine these into one large dataframe for analyses. How can we do this programmatically?** 


In words, describe what are the steps to solve the challenge: 

- load 17 files and combine them into one dataset
- 
- 

How would you solve this problem using existing knowledge: 

-manual step
-repeat code
-

Try solving this in R using new skills:

```{r, learner-solutions}
#list.files("data/penguin_distributions/")
  
penguins_combined <- list.files("data/penguin_distributions/",pattern= ".csv", full.names= TRUE)|>
  map(read_csv) |>  #if we do not want the names to show we add (read_csv, show_col_type=TYPE)
  list_rbind()

view(penguins_combined)
unique(penguins_combined$species)
```

Demonstrator solutions: 

```{r, instructor-solutions}


```

## Challenge 1 - Import common names

We only have latin names for each species of penguin but we need common names for when we report our results to stakeholders. Our collaborator started compiling common names in a separate `.csv` in the `data/` folder. **Compile the common names for the remaining taxa and join these into the dataframe `penguins_combined`. You may need to import the `penguins_combined.csv` into R first. 

In words, describe what are the steps to solve the challenge: 

- 
- 
- 

How would you solve this problem using existing knowledge: 

-
-
-

Try solving this in R using new skills:

```{r, learner-solutions}

```

Demonstrator solutions: 

```{r, instructor-solutions}


```


## Challenge 2 - Add n_records as a column

For your analysis, you need to calculate the total number of records available for each species, and add that as a new column in your data.

In words, describe what are the steps to solve the challenge: 

- 
- 
- 

How would you solve this problem using existing knowledge: 

-
-
-

Try solving this in R using new skills:

```{r, learner-solutions}
# counting the number of individuals within the dataset 
# Count the number of individuals by species
penguins_counts <- penguins_combined %>%
  group_by(species) %>%
  summarise(count = n())

# creating new column with the total number of records
penguins_with_counts <- penguins_combined %>%
  left_join(penguins_counts, by = "species")

penguins_with_counts
```

Demonstrator solutions: 

```{r, instructor-solutions}


```


## Challenge 3 - Determine the top 3 most recorded taxa

We need to know which are the top 3 species that we have the the most records. Can you figure which species are these?

In words, describe what are the steps to solve the challenge: 

- 
- 
- 

How would you solve this problem using existing knowledge: 

-
-
-

Try solving this in R using new skills:

```{r, learner-solutions}

```

Demonstrator solutions: 

```{r, instructor-solutions}


```


## Challenge 4 - Excluding rogue data

We need to clean the data a little before we analyse it. Clean the data so that we have

- Individual counts > 0
- Observations from iNaturalist and eBird using the `institutionCode` (the code for eBird is confusingly "CLO"; the code for iNaturalist is more sensibly "iNaturalist")

Export this dataset as a `.csv`

In words, describe what are the steps to solve the challenge: 

- 
- 
- 

How would you solve this problem using existing knowledge: 

-
-
-

Try solving this in R using new skills:

Step 1 
```{r, learner-solutions}
cleaned_penguins <- penguins_combined %>%
  filter(individualCount > 0, 
         institutionCode %in% c("iNaturalist", "CLO"))
```

Step 2

```{r}
write_csv(cleaned_penguins, "data/cleaned_penguins.csv")
```


## Challenge 5 - Add Size information

We need to get compute the average bill and flipper dimensions using the `penguin_sizes` data and nd merge this into the `penguins_combined` dataset. You name need to wrangle/create the penguin names a little

In words, describe what are the steps to solve the challenge: 

- Open the penguin data set
- Get averages of bill and flipper lenght and depth
- Change common names to scientific names 
- Join the sizes and the combined 

How would you solve this problem using existing knowledge: 

-
-
-mutate()

Try solving this in R using new skills:

Step 1
```{r, learner-solutions}
library(dplyr)
penguin_sizes<- read_csv("data/penguin_sizes.csv")

penguin_sizes
```

Step 2
```{r}
# Calculate the average values for bill length, bill depth, and flipper length for each species
penguin_averages <- penguin_sizes %>%
  group_by(species) %>%
  summarise(
    avg_bill_length = mean(bill_length_mm, na.rm = TRUE),
    avg_bill_depth = mean(bill_depth_mm, na.rm = TRUE),
    avg_flipper_length = mean(flipper_length_mm, na.rm = TRUE)
  )
# Print the result
print(penguin_averages)
```

Step 3
```{r}
#change the names from common to scientific
penguin_averages$species[penguin_averages$species == "Adelie"] <- "Pygoscelis adeliae"
penguin_averages$species[penguin_averages$species == "Gentoo"] <- "Pygoscelis papua"
penguin_averages$species[penguin_averages$species == "Chinstrap"] <- "Pygoscelis antarcticus"

#print to check new names
penguin_averages
```

Step 4
```{r}
sizes <- left_join(penguins_combined, penguin_averages, by="species")

dim(penguin_sizes)
dim(penguin_averages)
colnames(penguin_sizes)
colnames(penguin_averages)
colnames(sizes)

view(sizes)
```

Demonstrator solutions: 

```{r, instructor-solutions}


```


## Challenge 6 - Export data by year

Your collaborator at the museum requires the giant penguin dataset to be broken down and saved as `.csv` by year. Solve this challenge with code!!

In words, describe what are the steps to solve the challenge: 

- 
- 
- 

How would you solve this problem using existing knowledge: 

-
-
-

Try solving this in R using new skills:

```{r, learner-solutions}

```

Demonstrator solutions: 

```{r, instructor-solutions}


```


## Challenge 7 - How much do different penguin species migrate

Your penguin collaborator knows from natural history knowledge that some penguins migrate and others don't but no one has ever quantified this.  Calculate the difference between the summer median latitude and the winter median latitude for each species.  (Median is more robust to outliers so that's more appropriate here compared to the mean.) Note there may be species with missing data for certain seasons and this may lead to missing species in the final plot. 

Make a plot of species by degrees latitude migrated.    

In words, describe what are the steps to solve the challenge: 

- 
- 
- 

How would you solve this problem using existing knowledge: 

-
-
-

Try solving this in R using new skills:

```{r, learner-solutions}

```


Demonstrator solutions: 

```{r, instructor-solutions}


```


## Challenge 8 - Lots of descriptive statistics

We need to report on some descriptive statistics of our penguin study. We need to know the following:

- How many different genera are represented in our dataset
- How many different species do we have for each genera
- Calculate the proportion of points from iNaturalist and eBird using the institutionCode (the code for eBird is confusingly "CLO"; the code for iNaturalist is more sensibly "iNaturalist")
- How many records by species
- How many records by year
- How many records by country code
- How many records by basis of record


In words, describe what are the steps to solve the challenge: 

- 
- 
- 

How would you solve this problem using existing knowledge: 

-
-
-

Try solving this in R using new skills:

```{r, learner-solutions}

```

Demonstrator solutions: 

```{r, instructor-solutions}


```


## Challenge 9 - Facet plot and export plots

We want some good visualisations of our data.

a. Make a multipanel plot of global distribution of penguins, with a panel for each genus
b. Make a multipanel plot of by month
c. Make a multipanel plot of by genus on the y-axis and individual count (<10 or >=10) on the x-axis

In words, describe what are the steps to solve the challenge: 

- 
- 
- 

How would you solve this problem using existing knowledge: 

-
-
-

Try solving this in R using new skills:

```{r, learner-solutions}

```

Demonstrator solutions: 

```{r, instructor-solutions}
  
```


## Challenge 10 - Plot country x species presence-absence

You want to make a graph of country x species, colouring for each species if it present in each country.

In words, describe what are the steps to solve the challenge: 

- 
- 
- 

How would you solve this problem using existing knowledge: 

-
-
-

Try solving this in R using new skills:

```{r, learner-solutions}

```

Demonstrator solutions: 

```{r, instructor-solutions}


```


## Challenge 11 - Make a lot of maps

Make a folder and make 19 pdfs, one for each penguin species, with a map of that species.  Make the title of the plot include both the common name of the speices and the scientific name.  Make the file name the scientific name.

In words, describe what are the steps to solve the challenge: 

- Get map and libraries 
- 
- 

How would you solve this problem using existing knowledge: 

-
-
-

#MAP 

```{r, instructor-solutions}
#library(tidyverse)
#library(ggplot2)
#library(maps)
#library(ggthemes)
#library(ggmaps)

af <- read_csv("data/penguin_distributions/Aptenodytes forsteri.csv")

# Get world map data
world_map <- map_data("world")

af$countdatapresent <- case_when (af$individualCount > 0 ~ "Count data present", .default = "No count data")

#mostly from chagpt:
# Create a ggplot object
#ggplot(world_map, aes(x = long, y = lat, group = group)) +
 # geom_polygon(color = "white") + # Fill the regions and outline with white
  #scale_fill_viridis_d() + # Use a viridis color scale for regions
  #theme_minimal() + # Apply a minimal theme
  #theme(
   # panel.background = element_rect(fill = "lightblue"),
    # Light blue background
    #panel.grid.major = element_blank(),
    # Remove major grid lines
    #panel.grid.minor = element_blank(),
    # Remove minor grid lines
    axis.title = element_blank(),
    # Remove axis titles
    axis.text = element_blank(),
    # Remove axis text
    axis.ticks = element_blank() # Remove the legend
  ) +
  coord_fixed(1.3) +
  geom_point(data = af,
             aes(
               x = decimalLongitude,
               y = decimalLatitude,
               group = NA,
               col = countdatapresent
             ))# Ensure the aspect ratio is correct

#ggsave("output/emperorpenguindist.pdf",
       width = 5,
       height = 8)
```

Make a map for one species

```{r}
#install.packages("maps")
library(ggplot2)
library(maps)
library(dplyr)

# filtering for one of the species types 



```

```{r}

make_map <- function(species_of_interest, common_name, df = penguins_combined) {
  species_data <- df %>%
  filter(species == species_of_interest)
  #generating a map for the plot
  world_map <- map_data("world")
  
  # plotting the first species
  p<-ggplot() +
    geom_map(
      data = world_map,
      map = world_map,
      aes(x = long, y = lat, map_id = region),
      fill = "lightgray",
      color = "white"
    ) +
    coord_fixed(ratio = 1.2) +
    geom_point(
      data = species_data,
      aes(x = decimalLongitude, y = decimalLatitude),
      colour = "lightgreen",
      size = 1.5
    ) +
    labs(
      title = paste0(
        "Distribution of ",
        common_name,
        " (",
        species_of_interest,
        ") ",
        "from GBIF"
      ),
      x = "Longitude",
      y = "Latitude"
    ) +
    theme_minimal()
  
  ggsave(paste0("output/", common_name, ".pdf"),
         width = 11,
         height = 8)
  return(p)
  }

make_map(df=penguins_combined,
         species_of_interest = "Pygoscelis adeliae",
         common_name = "Adeliae")
common_df <- read_csv("data/penguin_common_names.csv")
penguins_combined_with_common <- left_join(penguins_combined,common,by=c("species"="scientific_name"))


species <- unique(common_df$scientific_name)
common <- unique(common_df$common_name)

a<-make_map(species[5],common[5],penguins_combined)
b<-make_map(species[10],common[10],penguins_combined)
library(patchwork)
(a+b)/a

map2(species,common,make_map)
```

## Challenge 12 - Fit lots of models

In your analyses, sometimes you need to fit one complex model, other times you might be fitting many seperate models. How do we do that efficiently?

You been asked to fit a linear model between log_count and latitude, for each speces. Fit the models and extract the r2 for each model fit.

In words, describe what are the steps to solve the challenge: 

- 
- 
- 

How would you solve this problem using existing knowledge: 

-
-
-

Try solving this in R using new skills:

```{r, learner-solutions}

```

Demonstrator solutions: 

```{r, instructor-solutions}


```



## Challenge 13 - Combining nest and map
